########################################################################################################
# align_snake
#   Snakemake workflow to  download fastq files and associated metadata from SRA, then use STARsolo to align and quantify 10x Chromium datasets, and finally perform simple preprocessing so that data are ready for downstream analysis
#   Written by David W. McKellar
########################################################################################################
import pandas as pd
from itertools import chain
from functools import reduce
from os import path, remove, rename

########## Config files ##########
configfile:"config.yaml"
CHEMISTRY_SHEET = pd.read_csv(config["CHEMISTRY_SHEET"], na_filter=False,index_col=0)#"resources/chemistry_sheet.csv"

########## Executables ##########
FFQ_EXEC = config["FFQ_EXEC"]
PREFETCH_EXEC = config["PREFETCH_EXEC"]
FQD_EXEC = config["FQD_EXEC"]
BAM2FQ_EXEC = config["BAM2FQ_EXEC"]
STAR_EXEC = config["STAR_EXEC"]
GGET_EXEC = config["GGET_EXEC"]
FASTQC_EXEC = config["FASTQC_EXEC"]
# TRIMGALORE_EXEC = config["TRIMGALORE_EXEC"]
CUTADAPT_EXEC = config["CUTADAPT_EXEC"]
SAMTOOLS_EXEC = config["SAMTOOLS_EXEC"]
UMITOOLS_EXEC = config["UMITOOLS_EXEC"]
QUALIMAP_EXEC = config["QUALIMAP_EXEC"]
MULTIQC_EXEC = config["MULTIQC_EXEC"]


########## Directories ##########
PRODIR = config["PRODIR"] #Project parent directory - `.../scMuscle2`
METADIR = config["METADIR"] # Metadata directory - `.../scMuscle2/meta`
TMPDIR = config["TMPDIR"] # temporary files - `.../scMuscle2/tmp`
DATADIR = config["DATADIR"] # outputs for STAR alignment, etc - `.../scMuscle2/data`
REFDIR = config["REFDIR"] # Output for reference genomes - `.../scMuscle2/refs`
CACHEDIR = config["CACHEDIR"] # Directory for cached h5ad files - `.../scMuscle2/cache`


########## Metadata ##########
META = pd.read_csv(config["SAMPLE_SHEET"], na_filter=False)#encoding = "utf-8"

# Metadata filtering
META = META[list(META["include"])] #remove undesired samples ("include"==False)
META = META[list(META["file.format"]!="ERR")] #remove samples with file format issues
META = META[list(META["file.format"]!="ngdc_fastq")] #remove samples with file format issues
# META = META[list(META["file.format"]!="aws")] 

## Tissue filtering
# META = META[list(META["tissue"]=="muscle")]
META = META[[x in ["muscle", "tendon", "limb", "ligament", "cartilage"] for x in META["tissue"]]] # "heart"
META = META[list(META["tissue"]!="")]

## Species filtering
META = META[[x in ["Homo sapiens", "Mus musculus"] for x in META["species"]]] #  "Danio rerio"

META = META[list(META["GSM.accession"]!="NA")]
META = META[list(META["GSM.accession"]!="")]

META = META[[x in ["3p_v2", "3p_v3", "3p_v3.1", "5p_v1", "5p_v3"] for x in META["chemistry"]]]

# META = META.iloc[[100,101,102],:] # subset to only download certain samples [for debugging]


########## Pre-snake metadata prep ##########
## Prep for each **SRR** ID ~~~
# Get list of SRR IDs for fastq downloading
SRR_LIST = list(META["SRR.accession"])
for i in range(0,len(SRR_LIST)):
    SRR_LIST[i] = SRR_LIST[i].split(";")
SRR_LIST = list(chain(*SRR_LIST))

## Prep for each **GSM** ID ~~~
# Grab sample IDs and their associated fastqs
SAMPLES = META["GSM.accession"].unique()

# Build dictionary of SRR IDs/fastq files
# Build dictionaries of chemistries & species to use for alignment
SRR_DICT = {}
CHEM_DICT = {}
FORMAT_DICT = {}
SPECIES_DICT = {}
LINK_DICT = {}
for i in range(0,META.shape[0]):
    GSM = list(META["GSM.accession"])[i]

    TMP_SRR = META["SRR.accession"][list(META["GSM.accession"]==GSM)].values[0]
    SRR_DICT[GSM] = TMP_SRR.split(";") #Might need to change

    CHEM_DICT[GSM] = list(META["chemistry"])[i]
    FORMAT_DICT[GSM] = list(META["file.format"])[i]

    SPECIES_DICT[GSM] = list(META["species"])[i]
    SPECIES_DICT[GSM] = SPECIES_DICT[GSM].lower().replace(" ", "_")

    if list(META["file.link"])[i] != "NA":
        LINK_DICT[GSM] = list(META["file.link"])[i]


########## Reference genome info ##########
SPECIES = list(META["species"]) #all lowercase and underscores (no spaces!)
SPECIES = [x.lower() for x in SPECIES]
SPECIES = [x.replace(" ", "_") for x in SPECIES]
SPECIES = pd.unique(SPECIES)

########## Snakemake ##########
rule all:
    input:
        expand(
            "{DATADIR}/atlas/{SPECIES}.h5ad", 
            DATADIR=DATADIR,
            SPECIES=SPECIES
        ),
        expand(
            "{DATADIR}/align_out/{sample}/STARsolo/Solo.out/GeneFull/{status}/preDecon.h5ad", 
            DATADIR=config["DATADIR"], 
            sample=SAMPLES, 
            status=["raw","filtered"]
        ),
        # expand( #TODO cellbender output
        #     "{DATADIR}/align_out/{sample}/STARsolo/Solo.out/GeneFull/cellbender/deconQC.h5ad", 
        #     DATADIR=config["DATADIR"], 
        #     sample=SAMPLES
        # ), 
        expand( # soupx output, with metadata
            "{DATADIR}/align_out/{sample}/STARsolo/Solo.out/GeneFull/soupx/deconQC_meta.h5ad", 
            DATADIR=config["DATADIR"], 
            sample=SAMPLES
        ),         
        # expand( # alignment QC with qualimap)
        #     "{DATADIR}/align_out/{sample}/qualimap_out/qualimapReport.html", 
        #     DATADIR=config["DATADIR"],
        #     sample=SAMPLES
        # ), 
        # expand( # umi_tools deduplicated .bam **Note** this is slow!! 
        #     "{DATADIR}/align_out/{sample}/STARsolo/Aligned.sortedByCoord.dedup.out.bam.bai", 
        #     DATADIR=config["DATADIR"], 
        #     sample=SAMPLES
        # ), 
        expand( # compress unmapped reads
            "{DATADIR}/align_out/{sample}/STARsolo/Unmapped.out.mate2.fastq.gz", 
            DATADIR=config["DATADIR"], 
            sample=SAMPLES
        ), 
        expand( # compressed count matrices
            "{DATADIR}/align_out/{sample}/STARsolo/Solo.out/Gene/filtered/matrix.mtx.gz", 
            DATADIR=config["DATADIR"], 
            sample=SAMPLES
        ), 
        expand( # index non-dedup .bam 
            "{DATADIR}/align_out/{sample}/STARsolo/Aligned.sortedByCoord.out.bam.bai", 
            DATADIR=config["DATADIR"], 
            sample=SAMPLES
        ), 
        expand( # raw R2 fastQC results
            "{DATADIR}/align_out/{sample}/fastqc_preTrim_R2", 
            DATADIR=config["DATADIR"], 
            sample=SAMPLES
        ), 
        expand( # adapter/polyA/ployG-trimmed R2 fastQC results
            "{DATADIR}/align_out/{sample}/fastqc_postTrim_R2", 
            DATADIR=config["DATADIR"], 
            sample=SAMPLES
        ), 
        expand( # unmapped R2 fastQC results
            "{DATADIR}/align_out/{sample}/fastqc_unmapped_R2", 
            DATADIR=config["DATADIR"],
            sample=SAMPLES
        ), 
        expand( # Reference genomes
            "{REFDIR}/{SPECIES}/STAR/Genome", 
            REFDIR=REFDIR, 
            SPECIES=SPECIES
        ), 
        expand( # metadata files
            "{METADIR}/{SRR}.json", 
            METADIR=config["METADIR"], 
            SRR=SRR_LIST
        ),
        expand( # merged metadata table, containing info from GEO, etc.
            "{PRODIR}/merged_metadata.csv", 
            PRODIR=config["PRODIR"]
        )

# Import rules
## Download metadata and raw data
include: "rules/1_write_SRR_list.smk"
include: "rules/1_get_metadata.smk"
include: "rules/1_get_fqs_v2.smk"

## Aggregate and trim raw read data
include: "rules/2_trimQC.smk"

## Alignment, post-alignment clean-up, and QC with STARsolo
include: "rules/3_star_build_ref.smk"
include: "rules/3_star_align.smk"
include: "rules/3_dedup.smk"
include: "rules/3_star_unmapped.smk" #TODO- necessary?
include: "rules/3_qualimap.smk"

## Counts preprocessing
include: "rules/4a_scanpy_init.smk" 
include: "rules/4b_soupx.smk" 
# include: "rules/4b_cellbender.smk" #TODO
include: "rules/4c_scanpy_QCfilter.smk" 

## Final data aggregation and QC
include: "rules/5_atlas_init.smk"
# include: "rules/5_multiqc.smk"
