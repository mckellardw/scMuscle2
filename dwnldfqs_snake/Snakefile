########################################################################################################
# dwnldfqs_snake
#   Snakemake workflow to download fastq files and associated metadata from SRA
#   v1.0
#   Written by David McKellar
#   Last edited: --/--/--, DWM
########################################################################################################

import pandas as pd
from itertools import chain
from functools import reduce
from os import path, remove, rename

########################################################################################################
# Config file
########################################################################################################
configfile:'config.yaml'

########################################################################################################
# Directories and locations
########################################################################################################
TMPDIR = config['TMPDIR']
PRODIR = config['PRODIR']
METADIR = config['METADIR']

shell("mkdir -p {TMPDIR}")
shell("mkdir -p {PRODIR}")
shell("mkdir -p {METADIR}")

########################################################################################################
# Variables and references
########################################################################################################
META = pd.read_csv(config['SAMPLE_SHEET'], na_filter=False)

META = META[list(META['include'])] #remove undesired samples ('include'==False)

# Filter for samples with fastq's available
META = META[list(META['file.format']=="bam")]
META = META[list(META['tissue']=="muscle")]

# META = META.iloc[1:4,:] # subset to only download certain samples...

SRR = list(META['SRR.accession'])
# print(SRR)
for i in range(0,len(SRR)):
    SRR[i] = SRR[i].split(";")
SRR = list(chain(*SRR))

# print(SRR[range(1,12)])

########################################################################################################
# Executables
########################################################################################################
FFQ = config["FFQ"]
PREFETCH = config["PREFETCH"]
PFD = config["PFD"]
BAM2FQ = config["BAM2FQ"]

########################################################################################################
########################################################################################################
rule all:
    input:
        expand('{PRODIR}/data/fastqs/{sample}_{READ}.fastq.gz', PRODIR=config['PRODIR'], sample=SRR, READ=["R1", "R2"]), # R1 fastq
        expand('{TMPDIR}/{sample}.txt', TMPDIR=config['TMPDIR'], sample=SRR), #
        expand('{METADIR}/{sample}.json', METADIR=config['METADIR'], sample=SRR), # metadata files
        expand('{METADIR}/merged_metadata.csv', METADIR=config['METADIR'])

#############################################
## Get metadata with `ffq`
#############################################
# Download metadata for each individual SRR (run) ID
## Info: https://github.com/pachterlab/ffq
rule get_metadata:
    output:
        METAJSON = '{METADIR}/{sample}.json'
    shell:
        """
        {FFQ} -o {output.METAJSON} {wildcards.sample}
        """

# Combine ffq-downloaded .json's into a big csv for parsing
rule merge_metadata:
    input:
        expand('{METADIR}/{sample}.json', METADIR=config['METADIR'], sample=SRR)
    output:
        METACSV = '{METADIR}/merged_metadata.csv'
    run:
        df_list = list()
        for f in input: # load metadata files for each sample
            with open(f) as data_file:
                data = json.load(data_file)
            df = pd.json_normalize(data).T
            tmp = df.index[0].split('.')[0] + '.' # Get SRR ID...
            df = df.rename(index = lambda x: x.strip(tmp)) # Remove SRR ID from row names
            df_list.append(df.T) # transpose so that each row is a different run

        print("Concatenating metadata...")
        df_out = pd.concat(df_list)

        df_out.to_csv(output.METACSV, index=False)


#############################################
## prefetch (SRA-toolkit)
#############################################
# Download reads as an SRA file into a temporary directory, so they can be formatted as .fastq's
# Data uploaded as a .bam is downloaded in the original format (.bam file) which will later be converted to .fastq
rule prefetch:
    output:
        SRA_check = temp("{TMPDIR}/{sample}.txt")
    params:
        # TMPDIR=TMPDIR,
        # SRA_tmp = "{TMPDIR}/{sample}.sra",
        SRA_BAM = '{TMPDIR}/{sample}.bam',
        UPLOADTYPE = lambda wildcards: \
            META.loc[[wildcards.sample in srr_id for srr_id in META['SRR.accession']],"file.format"].values[0]
    run:
        if params.UPLOADTYPE == "fastq":
            shell(
                """
                echo "Prefetching SRA files for {wildcards.sample}"

                {PREFETCH} \
                --verify yes \
                --max-size 999999999999 \
                --output-directory {TMPDIR} \
                {wildcards.sample} \
                && echo fastq > {output.SRA_check}
                """
            )
        elif params.UPLOADTYPE == "bam":
            #TODO- check for/remove extra files from SRA
            shell(
            #Downloaded bams are not readable....
                """
                cd {TMPDIR}

                {PREFETCH} \
                --verify yes \
                --max-size 999999999999 \
                --force ALL \
                --output-directory {TMPDIR}/{wildcards.sample} \
                --type all \
                {wildcards.sample}

                mv $(ls -a {TMPDIR}/{wildcards.sample}/*.bam) {TMPDIR}/{wildcards.sample}.bam
                echo bam > {output.SRA_check}
                """
            )
            # --output-file {SRA_BAM} \
            #find {TMPDIR}/{wildcards.sample} -name

#############################################
## parallel-fastq-dump
##      https://github.com/rvalieris/parallel-fastq-dump
#############################################
 # Convert SRA files to fastq with parallel-fastq-dump
 #TODO: handle bam files
rule get_fastqs:
    input:
        SRA_check = TMPDIR+"/{sample}.txt"
    output:
        R1_FQ = '{PRODIR}/data/fastqs/{sample}_1.fastq.gz',
        R2_FQ = '{PRODIR}/data/fastqs/{sample}_2.fastq.gz'
    params:
        # TMPDIR = TMPDIR,
        SRA_tmp = TMPDIR+'/{sample}.sra',
        SRA_BAM = TMPDIR+'/{sample}.bam',
        UPLOADTYPE = lambda wildcards: \
            META.loc[[wildcards.sample in srr_id for srr_id in META['SRR.accession']],"file.format"].values[0],
        # UPLOADTYPE="bam", #for debugging
        OUTDIR = '{PRODIR}/data/fastqs/'
    threads:
        config["THREADS"]
    run:
        if params.UPLOADTYPE == "fastq":
            shell(
                """
                echo "Converting SRA files to .fastq's for {wildcards.sample}"
                {PFD} \
                --sra-id {params.SRA_tmp} \
                --threads {threads} \
                --outdir {params.OUTDIR} \
                --tmpdir {TMPDIR} \
                --split-files \
                --gzip && \
                rm {params.SRA_tmp}
                """
            )
        elif params.UPLOADTYPE == "bam":
            #TODO- remove extra files in {TMPDIR}/{wildcards.sample}/...
            shell(
                """
                {BAM2FQ} \
                --nthreads {threads} \
                --reads-per-fastq=999999999999999 \
                {params.SRA_BAM} \
                {TMPDIR}/{wildcards.sample}/b2f/

                zcat $(find {TMPDIR}/{wildcards.sample}/b2f/ -name *R1*.fastq.gz) > {params.OUTDIR}/{wildcards.sample}_1.fastq
                zcat $(find {TMPDIR}/{wildcards.sample}/b2f/ -name *R2*.fastq.gz) > {params.OUTDIR}/{wildcards.sample}_2.fastq

                pigz -p {threads} {params.OUTDIR}/{wildcards.sample}_*.fastq
                """
            )

# {FFQ} --ncbi {sample} \
# | xargs curl -o {PRODIR}/data/fastqs/{sample}.bam

# Other option:
# ffq --ftp SRR7276476 | grep -Eo '"url": "[^"]*"' | grep -o '"[^"]*"$' | xargs curl -O

# Check fastq sizes, then rename/label files for R1 & R2 (discard I1)
#TODO- account for dual index (v3.1) samples!!
rule rename_fastqs:
    input:
        R1_FQ = '{PRODIR}/data/fastqs/{sample}_1.fastq.gz',
        R2_FQ = '{PRODIR}/data/fastqs/{sample}_2.fastq.gz'
    output:
        R1_FQ = '{PRODIR}/data/fastqs/{sample}_R1.fastq.gz',
        R2_FQ = '{PRODIR}/data/fastqs/{sample}_R2.fastq.gz'
    params:
        OUTDIR = '{PRODIR}/data/fastqs/',
        UPLOADTYPE = lambda wildcards: \
            META.loc[[wildcards.sample in srr_id for srr_id in META['SRR.accession']],"file.format"].values[0]
    run:
        #TODO- rewrite this into a function to clean up snakemake code...
        if params.UPLOADTYPE == "fastq":
            # Check for file sizes (R2 is biggest, then R1, then I2 & I1)
            if path.exists(f'{PRODIR}/data/fastqs/{wildcards.sample}_4.fastq.gz'):
                sra_sizes = {
                    f'{PRODIR}/data/fastqs/{wildcards.sample}_1.fastq.gz': path.getsize(f'{PRODIR}/data/fastqs/{wildcards.sample}_1.fastq.gz'),
                    f'{PRODIR}/data/fastqs/{wildcards.sample}_2.fastq.gz': path.getsize(f'{PRODIR}/data/fastqs/{wildcards.sample}_2.fastq.gz'),
                    f'{PRODIR}/data/fastqs/{wildcards.sample}_3.fastq.gz': path.getsize(f'{PRODIR}/data/fastqs/{wildcards.sample}_3.fastq.gz'),
                    f'{PRODIR}/data/fastqs/{wildcards.sample}_4.fastq.gz': path.getsize(f'{PRODIR}/data/fastqs/{wildcards.sample}_4.fastq.gz')
                }
                rename_dict = {
                    'R2': max(sra_sizes),
                    'R1': list(sra_sizes.keys())[list(sra_sizes.values()).index(sorted(sra_sizes.values())[-3])],
                    'I2': list(sra_sizes.keys())[list(sra_sizes.values()).index(sorted(sra_sizes.values())[-2])],
                    'I1': min(sra_sizes)
                }

                remove(rename_dict['I2'])
                remove(rename_dict['I1'])
                rename(rename_dict['R1'], f'{PRODIR}/data/fastqs/{wildcards.sample}_R1.fastq.gz')
                rename(rename_dict['R2'], f'{PRODIR}/data/fastqs/{wildcards.sample}_R2.fastq.gz')
            elif path.exists(f'{PRODIR}/data/fastqs/{wildcards.sample}_3.fastq.gz'):
                sra_sizes = {
                    f'{PRODIR}/data/fastqs/{wildcards.sample}_1.fastq.gz': path.getsize(f'{PRODIR}/data/fastqs/{wildcards.sample}_1.fastq.gz'),
                    f'{PRODIR}/data/fastqs/{wildcards.sample}_2.fastq.gz': path.getsize(f'{PRODIR}/data/fastqs/{wildcards.sample}_2.fastq.gz'),
                    f'{PRODIR}/data/fastqs/{wildcards.sample}_3.fastq.gz': path.getsize(f'{PRODIR}/data/fastqs/{wildcards.sample}_3.fastq.gz')
                }
                rename_dict = {
                    'R2': max(sra_sizes),
                    'R1': list(sra_sizes.keys())[list(sra_sizes.values()).index(sorted(sra_sizes.values())[-2])],
                    'I1': min(sra_sizes)
                }

                remove(rename_dict['I1'])
                rename(rename_dict['R1'], f'{PRODIR}/data/fastqs/{wildcards.sample}_R1.fastq.gz')
                rename(rename_dict['R2'], f'{PRODIR}/data/fastqs/{wildcards.sample}_R2.fastq.gz')
            else:
                sra_sizes = {
                    f'{PRODIR}/data/fastqs/{wildcards.sample}_1.fastq.gz': path.getsize(f'{PRODIR}/data/fastqs/{wildcards.sample}_1.fastq.gz'),
                    f'{PRODIR}/data/fastqs/{wildcards.sample}_2.fastq.gz': path.getsize(f'{PRODIR}/data/fastqs/{wildcards.sample}_2.fastq.gz')
                }

                rename_dict = {
                    'R2': max(sra_sizes),
                    'R1': min(sra_sizes)
                }

                rename(rename_dict['R1'], f'{PRODIR}/data/fastqs/{wildcards.sample}_R1.fastq.gz')
                rename(rename_dict['R2'], f'{PRODIR}/data/fastqs/{wildcards.sample}_R2.fastq.gz')
        elif params.UPLOADTYPE == "bam":
            #rename R1 & R2 files (can use R1 and R2 from file names here, not dependent on file sizes)
            shell(
                """
                mv {input.R1_FQ} {output.R1_FQ}
                mv {input.R2_FQ} {output.R2_FQ}
                """
            )
